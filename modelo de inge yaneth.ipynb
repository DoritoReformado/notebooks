{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from shapely import wkt\n",
    "from shapely.errors import WKTReadingError\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely import Polygon\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "login = {\n",
    "    \"username\":\"Dorito\",\n",
    "    \"password\":\"Portador123\"\n",
    "}\n",
    "# Crear una sesi√≥n para mantener la cookie\n",
    "session = requests.Session()\n",
    "response = session.post(\"https://192.168.179.3/api/user/login/\", login, verify=False)\n",
    "\n",
    "def get_data_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesi√≥n para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://192.168.179.3/api/user/login/\", login, verify=False)\n",
    "    datos = []\n",
    "    while url:\n",
    "        response = session.get(url, verify=False)\n",
    "        info = response.json()\n",
    "        datos.extend(info[\"results\"])\n",
    "        url = info[\"next\"]\n",
    "    return datos\n",
    "\n",
    "def get_data_not_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesi√≥n para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://192.168.179.3/api/user/login/\", login, verify=False)\n",
    "    response = session.get(url, verify=False)\n",
    "    info = response.json()\n",
    "    return info\n",
    "\n",
    "\n",
    "def parse_geom_safe(wkt_string):\n",
    "    try:\n",
    "        if isinstance(wkt_string, str) and \"SRID=\" in wkt_string:\n",
    "            return wkt.loads(wkt_string.split(\";\", 1)[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None  # simplemente ignora lo inv√°lido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "<H3>SCRIPT PARA BUSCAR INFO</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y normalizar datos\n",
    "url = \"https://192.168.179.3/api/v1/poligonos_lotes/\"\n",
    "url_productor = \"https://192.168.179.3/api/v1/productor/\"\n",
    "url_extensionista = \"https://192.168.179.3/api/v1/Extensionista/\"\n",
    "url_productor_data = \"https://192.168.179.3/api/v1/productor/mongo_get/productor_data/\"\n",
    "url_fincas = \"https://192.168.179.3/api/v1/poligonos_fincas/\"\n",
    "url_municipio = \"https://192.168.179.3/api/v1/municipio/\"\n",
    "url_departamento = \"https://192.168.179.3/api/v1/vereda/\"\n",
    "url_lotes = \"https://192.168.179.3/api/v1/poligonos_lotes/mongo_get/mongo_atribute/\"\n",
    "print(\"cargando datos lotes\")\n",
    "datos = get_data_paginated(url)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor = get_data_not_paginated(url_productor)\n",
    "print(\"cargando datos extensionista\")\n",
    "datos_extensionista = get_data_not_paginated(url_extensionista)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor_data = get_data_not_paginated(url_productor_data)\n",
    "print(\"cargando datos fincas\")\n",
    "datos_fincas = get_data_paginated(url_fincas)\n",
    "print(\"cargando datos lotes\")\n",
    "datos_lotes = get_data_not_paginated(url_lotes)\n",
    "print(\"Cargando datos municipios\")\n",
    "datos_municipios = get_data_not_paginated(url_municipio)\n",
    "print(\"cargando datos departamentos\")\n",
    "datos_departamentos = get_data_not_paginated(url_departamento)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.json_normalize(datos)\n",
    "df_productor = pd.json_normalize(datos_productor)\n",
    "df_extensionista = pd.json_normalize(datos_extensionista)\n",
    "df_productor_data = pd.json_normalize(datos_productor_data)\n",
    "df_fincas = pd.json_normalize(datos_fincas)\n",
    "df_lotes = pd.json_normalize(datos_lotes)\n",
    "df_municipio = pd.json_normalize(datos_municipios)\n",
    "df_departamento = pd.json_normalize(datos_departamentos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipio.to_excel(\"./municipios.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar productores que tienen postgres_data.id\n",
    "# df_productor = df_productor[df_productor[\"id\"].notna()]\n",
    "# Realizar los merge sin eliminar filas del DataFrame principal\n",
    "df_completo = df.merge(\n",
    "    df_productor,\n",
    "    left_on=\"productor\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_productor_data,\n",
    "    left_on=\"productor_data\",\n",
    "    right_on=\"_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_extensionista,\n",
    "    left_on=\"extensionista\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# df_completo = df_completo.merge(\n",
    "#     df_fincas,\n",
    "#     left_on=\"finca\",\n",
    "#     right_on=\"id\",\n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_lotes,\n",
    "    left_on=\"id_x\",\n",
    "    right_on=\"poligono_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ejemplo: renombrar id en municipio y departamento\n",
    "df_municipio = df_municipio.rename(columns={\"id\": \"id_municipio\"})\n",
    "df_departamento = df_departamento.rename(columns={\"id\": \"id_departamento\"})\n",
    "df_departamento = df_departamento.rename(columns={\"municipio\": \"alkdsjflkajs√±ldkfjasdl\"})\n",
    "\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_municipio,\n",
    "    left_on=\"municipio\",\n",
    "    right_on=\"id_municipio\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_departamento,\n",
    "    left_on=\"vereda\",\n",
    "    right_on=\"id_departamento\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_geom_safe(wkt_string):\n",
    "    try:\n",
    "        if isinstance(wkt_string, str) and \"SRID=\" in wkt_string:\n",
    "            return wkt.loads(wkt_string.split(\";\", 1)[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None  # simplemente ignora lo inv√°lido\n",
    "\n",
    "# Aplicar solo a las v√°lidas\n",
    "df_completo[\"geometry\"] = df_completo[\"poligono\"].apply(parse_geom_safe)\n",
    "\n",
    "# Crear el GeoDataFrame sin que explote\n",
    "gdf = gpd.GeoDataFrame(df_completo, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y normalizar datos\n",
    "url = \"https://192.168.179.3/api/v1/poligonos_fincas/\"\n",
    "url_productor = \"https://192.168.179.3/api/v1/productor/\"\n",
    "url_lotes = \"https://192.168.179.3/api/v1/poligonos_fincas/mongo_get/mongo_atribute/\"\n",
    "print(\"cargando datos fincas\")\n",
    "datos = get_data_paginated(url)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor = get_data_not_paginated(url_productor)\n",
    "print(\"cargando datos fincas atributos\")\n",
    "datos_lotes = get_data_not_paginated(url_lotes)\n",
    "\n",
    "df = pd.json_normalize(datos)\n",
    "df_productor = pd.json_normalize(datos_productor)\n",
    "df_lotes = pd.json_normalize(datos_lotes)\n",
    "\n",
    "# Filtrar productores que tienen postgres_data.id\n",
    "df_productor = df_productor[df_productor[\"id\"].notna()]\n",
    "# Realizar los merge sin eliminar filas del DataFrame principal\n",
    "df_completo = df.merge(\n",
    "    df_productor,\n",
    "    left_on=\"productor\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_lotes,\n",
    "    left_on=\"id_x\",\n",
    "    right_on=\"poligono_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_extensionista,\n",
    "    left_on=\"extensionista\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Aplicar solo a las v√°lidas\n",
    "df_completo[\"geometry\"] = df_completo[\"poligono\"].apply(parse_geom_safe)\n",
    "\n",
    "# Crear el GeoDataFrame sin que explote\n",
    "gdf_fincas = gpd.GeoDataFrame(df_completo, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.validation import make_valid\n",
    "\n",
    "def filtrar_poligonos_superpuestos(gdf, umbral=0.01):\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # Asegurar que la fecha sea datetime\n",
    "    gdf[\"fecha\"] = pd.to_datetime(\n",
    "        gdf[\"fecha\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # Reparar geometr√≠as inv√°lidas\n",
    "    gdf[\"geometry\"] = gdf[\"geometry\"].apply(\n",
    "        lambda geom: make_valid(geom) if not geom.is_valid else geom\n",
    "    )\n",
    "\n",
    "    # Ordenar por fecha descendente (m√°s recientes primero)\n",
    "    gdf = gdf.sort_values(by=\"fecha\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    indices_validos = []\n",
    "\n",
    "    for i, row_i in gdf.iterrows():\n",
    "        print(f\"{i}/{len(gdf)-1}\")\n",
    "        geom_i = row_i.geometry\n",
    "        if geom_i is None or geom_i.is_empty:\n",
    "            continue\n",
    "\n",
    "        area_i = geom_i.area\n",
    "        keep = True\n",
    "\n",
    "        for j in indices_validos:\n",
    "            geom_j = gdf.loc[j, \"geometry\"]\n",
    "            if geom_j is None or geom_j.is_empty:\n",
    "                continue\n",
    "\n",
    "            area_j = geom_j.area\n",
    "\n",
    "            try:\n",
    "                inter = geom_i.intersection(geom_j).area\n",
    "            except Exception as e:\n",
    "                # Si no se puede intersectar, saltamos\n",
    "                print(f\"Error intersectando {i} y {j}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if inter > 0:\n",
    "                overlap = inter / min(area_i, area_j)\n",
    "                if overlap >= umbral:\n",
    "                    keep = False\n",
    "                    break\n",
    "\n",
    "        if keep:\n",
    "            indices_validos.append(i)\n",
    "\n",
    "    return gdf.loc[indices_validos].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def filtrar_poligonos_priorizar_pequenos(gdf, umbral=0.01):\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # Reparar geometr√≠as\n",
    "    gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda g: make_valid(g))\n",
    "\n",
    "    # Calcular √°reas\n",
    "    gdf[\"area\"] = gdf.geometry.area\n",
    "\n",
    "    # Peque√±os primero\n",
    "    gdf = gdf.sort_values(\"area\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    indices_validos = []\n",
    "\n",
    "    for i, row_i in gdf.iterrows():\n",
    "        geom_i = row_i.geometry\n",
    "        area_i = row_i.area\n",
    "\n",
    "        keep = True\n",
    "        \n",
    "        # Comparar con los ya aceptados (que son peque√±os o iguales)\n",
    "        for j in indices_validos:\n",
    "            geom_j = gdf.loc[j, \"geometry\"]\n",
    "            area_j = gdf.loc[j, \"area\"]\n",
    "\n",
    "            # No necesitamos verificar el caso contrario: j siempre es peque√±o o igual\n",
    "            inter = geom_i.intersection(geom_j).area\n",
    "            if inter > 0:\n",
    "                overlap = inter / min(area_i, area_j)\n",
    "                if overlap >= umbral:\n",
    "                    # geom_i (que es m√°s grande o igual) se elimina\n",
    "                    keep = False\n",
    "                    break\n",
    "        \n",
    "        if keep:\n",
    "            indices_validos.append(i)\n",
    "\n",
    "    return gdf.loc[indices_validos].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas = filtrar_poligonos_superpuestos(gdf_fincas,0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_habilidad = pd.read_excel(\"~/Descargas/HABILIDAD NOVIEMBRE 2025 COOCENTRAL.xlsx\", sheet_name=\"BASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_habilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cedulas = df_habilidad[\"CEDULA\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas[\"documento_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporte = []\n",
    "arreglo_productores_extensionista = []\n",
    "gdf = gdf.loc[gdf[\"documento_x\"].isin(lista_cedulas)]\n",
    "gdf_fincas = gdf_fincas.loc[gdf_fincas[\"documento_x\"].isin(lista_cedulas)]\n",
    "df_productor = df_productor.loc[df_productor[\"documento\"].isin(lista_cedulas)]\n",
    "for i, row in df_extensionista.iterrows():\n",
    "    gdf_lotes_extensionista = gdf.loc[gdf[\"extensionista\"] == row[\"id\"]]\n",
    "    numero_productores_visitados = len(gdf_lotes_extensionista[\"productor\"].unique())\n",
    "    gdf_fincas_extensionista = gdf_fincas.loc[gdf_fincas[\"extensionista\"] == row[\"id\"]]\n",
    "    productores_extensionista = df_productor.loc[df_productor[\"\" \\\n",
    "    \"extensionista\"] == row[\"id\"]]\n",
    "    print(gdf_lotes_extensionista)\n",
    "    reporte.append({\n",
    "        \"extensionista\":row[\"first_name\"] + \" \" +row[\"last_name\"],\n",
    "        \"numero_productores_con_poligono\": numero_productores_visitados,\n",
    "        \"numero_lotes_con_poligonos\": len(gdf_lotes_extensionista),\n",
    "        \"area_lotes_con_poligonos\": gdf_lotes_extensionista[\"area\"].sum(),\n",
    "        \"numero_fincas_con_poligono\": len(gdf_fincas_extensionista),\n",
    "        \"area_fincas_con_poligonos\": gdf_fincas_extensionista[\"area\"].sum(),\n",
    "        \"numero_productores_totales_BD_Sept\": len(productores_extensionista),\n",
    "        \"porcentaje_visitados\": (numero_productores_visitados/len(productores_extensionista))*100\n",
    "    })\n",
    "\n",
    "gdf_lotes_extensionista = gdf.loc[gdf[\"extensionista\"].isna()]\n",
    "numero_productores_visitados = len(gdf_lotes_extensionista[\"productor\"].unique())\n",
    "gdf_fincas_extensionista = gdf_fincas.loc[gdf_fincas[\"extensionista\"].isna()]\n",
    "productores_extensionista = df_productor.loc[df_productor[\"extensionista\"].isna()]\n",
    "# reporte.append({\n",
    "#     \"extensionista\": \"Desconocido\",\n",
    "#     \"numero_productores_visitados\": numero_productores_visitados,\n",
    "#     \"numero_productores_totales\": len(productores_extensionista),\n",
    "#     # \"porcentaje_visitados\": (numero_productores_visitados/len(productores_extensionista))*100,\n",
    "#     \"numero_lotes_visitados\": len(gdf_lotes_extensionista),\n",
    "#     \"numero_fincas_visitadas\": len(gdf_fincas_extensionista)\n",
    "# })\n",
    "\n",
    "gdf_lotes_extensionista = gdf\n",
    "numero_productores_visitados = len(gdf_lotes_extensionista[\"productor\"].unique())\n",
    "gdf_fincas_extensionista = gdf_fincas\n",
    "productores_extensionista = df_productor\n",
    "reporte.append({\n",
    "    \"extensionista\": \"Totales\",\n",
    "    \"numero_productores_con_poligono\": numero_productores_visitados,\n",
    "    \"numero_lotes_con_poligonos\": len(gdf_lotes_extensionista),\n",
    "    \"area_lotes_con_poligonos\": gdf_lotes_extensionista[\"area\"].sum(),\n",
    "    \"numero_fincas_con_poligono\": len(gdf_fincas_extensionista),\n",
    "    \"area_fincas_con_poligonos\": gdf_fincas_extensionista[\"area\"].sum(),\n",
    "    \"numero_productores_totales_BD_Sept\": len(productores_extensionista),\n",
    "    \"porcentaje_visitados\": (numero_productores_visitados/len(productores_extensionista))*100\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reportes = pd.DataFrame(reporte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reportes.to_excel(\"./REPORTE_ING_YANETH_15_12_2025.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lkajsfd√±lka√±jsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "<h2>AQUI COMIENZA EL ANALISIS DE VEREDAS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "from shapely import wkt\n",
    "from shapely.errors import WKTReadingError\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely import Polygon\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_safe(x):\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "login = {\n",
    "    \"username\":\"Dorito\",\n",
    "    \"password\":\"Portador123\"\n",
    "}\n",
    "# Crear una sesi√≥n para mantener la cookie\n",
    "session = requests.Session()\n",
    "response = session.post(\"https://produccion.local/api/user/login/\", login, verify=False)\n",
    "def get_data_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesi√≥n para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://produccion.local/api/user/login/\", login, verify=False)\n",
    "    datos = []\n",
    "    while url:\n",
    "        response = session.get(url, verify=False)\n",
    "        info = response.json()\n",
    "        datos.extend(info[\"results\"])\n",
    "        url = info[\"next\"]\n",
    "    return datos\n",
    "\n",
    "def get_data_not_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesi√≥n para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://produccion.local/api/user/login/\", login, verify=False)\n",
    "    response = session.get(url, verify=False)\n",
    "    info = response.json()\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y normalizar datos\n",
    "url = \"https://produccion.local/api/v1/poligonos_lotes/\"\n",
    "url_productor = \"https://produccion.local/api/v1/productor/\"\n",
    "url_productor_data = \"https://produccion.local/api/v1/productor/mongo_get/productor_data/\"\n",
    "url_fincas = \"https://produccion.local/api/v1/poligonos_fincas/\"\n",
    "url_municipio = \"https://produccion.local/api/v1/municipio/\"\n",
    "url_departamento = \"https://produccion.local/api/v1/vereda/\"\n",
    "url_lotes = \"https://produccion.local/api/v1/poligonos_lotes/mongo_get/mongo_atribute/\"\n",
    "print(\"cargando datos lotes\")\n",
    "datos = get_data_paginated(url)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor = get_data_not_paginated(url_productor)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor_data = get_data_not_paginated(url_productor_data)\n",
    "print(\"cargando datos fincas\")\n",
    "datos_fincas = get_data_paginated(url_fincas)\n",
    "print(\"cargando datos lotes\")\n",
    "datos_lotes = get_data_not_paginated(url_lotes)\n",
    "print(\"Cargando datos municipios\")\n",
    "datos_municipios = get_data_not_paginated(url_municipio)\n",
    "print(\"cargando datos departamentos\")\n",
    "datos_departamentos = get_data_not_paginated(url_departamento)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.json_normalize(datos)\n",
    "df_productor = pd.json_normalize(datos_productor)\n",
    "df_productor_data = pd.json_normalize(datos_productor_data)\n",
    "df_fincas = pd.json_normalize(datos_fincas)\n",
    "df_lotes = pd.json_normalize(datos_lotes)\n",
    "df_municipio = pd.json_normalize(datos_municipios)\n",
    "df_departamento = pd.json_normalize(datos_departamentos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipio.to_excel(\"./municipios.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departamento.to_excel(\"./veredas_base_datos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar productores que tienen postgres_data.id\n",
    "df_productor = df_productor[df_productor[\"id\"].notna()]\n",
    "# Realizar los merge sin eliminar filas del DataFrame principal\n",
    "df_completo = df.merge(\n",
    "    df_productor,\n",
    "    left_on=\"productor\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_productor_data,\n",
    "    left_on=\"productor_data\",\n",
    "    right_on=\"_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_fincas,\n",
    "    left_on=\"finca\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_lotes,\n",
    "    left_on=\"id_x\",\n",
    "    right_on=\"poligono_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ejemplo: renombrar id en municipio y departamento\n",
    "df_municipio = df_municipio.rename(columns={\"id\": \"id_municipio\"})\n",
    "df_departamento = df_departamento.rename(columns={\"id\": \"id_departamento\"})\n",
    "df_departamento = df_departamento.rename(columns={\"municipio\": \"alkdsjflkajs√±ldkfjasdl\"})\n",
    "\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_municipio,\n",
    "    left_on=\"municipio_x\",\n",
    "    right_on=\"id_municipio\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_departamento,\n",
    "    left_on=\"vereda_x\",\n",
    "    right_on=\"id_departamento\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el GeoDataFrame (con geometr√≠as inv√°lidas como None)\n",
    "\n",
    "def parse_geom_safe(wkt_string):\n",
    "    try:\n",
    "        if isinstance(wkt_string, str) and \"SRID=\" in wkt_string:\n",
    "            return wkt.loads(wkt_string.split(\";\", 1)[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None  # simplemente ignora lo inv√°lido\n",
    "\n",
    "# Aplicar solo a las v√°lidas\n",
    "df_completo[\"geometry\"] = df_completo[\"poligono_x\"].apply(parse_geom_safe)\n",
    "\n",
    "# Crear el GeoDataFrame sin que explote\n",
    "gdf = gpd.GeoDataFrame(df_completo, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Validaci√≥n de cantidad\n",
    "# assert len(gdf) == 10530, f\"Se esperaban 10530 registros, pero hay {len(gdf)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_habilidad = pd.read_excel(r\"C:\\Users\\dorito\\Downloads\\HABILIDAD SEPTIEMBRE 2025 COOCENTRAL(3.622) - UNIDAD TECNICA (1).xlsx\", sheet_name=\"BASE \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_ext_nuevos = ['YEISON FABIAN FIGUEROA SAENZ', 'JHOAN JERONIMO ORDO√ëEZ MU√ëOZ','ALEXANDER TORREJANO', 'CESAR POVEDA SILVA']\n",
    "# df_nuevas_zonas = df_habilidad.loc[df_habilidad[\"TECNICO DE LA ZONA 2025\"].isin(lista_ext_nuevos)]\n",
    "df_nuevas_zonas = df_habilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cedulas = df_nuevas_zonas[\"CEDULA\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departamento.columns = [\"id_vereda\", \"vereda_nombre\", \"poligono_vereda\", \"poligono_municipio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtro = gdf.loc[gdf[\"documento\"].isin(lista_cedulas)]\n",
    "gdf_filtro.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_habilidad.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion_en_limpio = []\n",
    "for i, row in df_nuevas_zonas.iterrows():\n",
    "    gdf_filtro_productor = gdf_filtro.loc[gdf_filtro[\"documento\"] == row[\"CEDULA\"]]\n",
    "    vereda = row['VEREDA ']\n",
    "    municipio = row['MUNICIPIO']\n",
    "    if not gdf_filtro_productor.empty:\n",
    "        vereda = df_departamento[\"id_vereda\"].loc[df_departamento[\"id_vereda\"] == gdf_filtro_productor[\"vereda_x\"].iloc[0]].iloc[0]\n",
    "        municipio = df_departamento[\"poligono_municipio\"].loc[df_departamento[\"id_vereda\"] == gdf_filtro_productor[\"vereda_x\"].iloc[0]].iloc[0]\n",
    "    informacion_en_limpio.append({\n",
    "        \"documento\": row[\"CEDULA\"],\n",
    "        \"nombre_completo\": row[\"NOMBRES Y APELLIDOS\"],\n",
    "        \"municipio\": municipio,\n",
    "        \"vereda\": vereda,\n",
    "        \"extensionista\": row['TECNICO DE LA ZONA 2025']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados = pd.DataFrame(informacion_en_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departamento.columns = ['id_vereda', 'vereda', 'poligono_vereda', 'id_municipio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "import geopandas as gpd\n",
    "\n",
    "# 1. Convertir WKT con SRID a geometr√≠as Shapely\n",
    "def limpiar_wkt(wkt_text):\n",
    "    if isinstance(wkt_text, str):\n",
    "        # Quitar el SRID=4326; si existe\n",
    "        if wkt_text.upper().startswith(\"SRID\"):\n",
    "            wkt_text = wkt_text.split(\";\", 1)[1]\n",
    "        return wkt.loads(wkt_text)\n",
    "    return None\n",
    "\n",
    "df_departamento[\"geometry\"] = df_departamento[\"poligono_vereda\"].apply(limpiar_wkt)\n",
    "gdf_veredas = gpd.GeoDataFrame(df_departamento, geometry=\"geometry\", crs=4326)\n",
    "df_municipio[\"geometry\"] = df_municipio[\"poligono_municipio\"].apply(limpiar_wkt)\n",
    "gdf_municipio = gpd.GeoDataFrame(df_municipio, geometry=\"geometry\", crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "for i, row in df_veredas_asociados.iterrows():\n",
    "    municipio = row[\"municipio\"]\n",
    "\n",
    "    # ------------------------------\n",
    "    # 1Ô∏è‚É£ PROCESAR MUNICIPIO (igual que antes)\n",
    "    # ------------------------------\n",
    "    if isinstance(municipio, str):\n",
    "        filtro = gdf_municipio[gdf_municipio[\"municipio\"].str.lower() == municipio.lower()]\n",
    "\n",
    "        if len(filtro) > 0:\n",
    "            municipio = filtro.iloc[0][\"id_municipio\"]\n",
    "            df_veredas_asociados.at[i, \"municipio\"] = municipio\n",
    "        else:\n",
    "            print(f\"No se encontr√≥ municipio exacto: {municipio}\")\n",
    "            continue\n",
    "\n",
    "    # ------------------------------\n",
    "    # 2Ô∏è‚É£ PROCESAR VEREDA (exacto + fuzzy local)\n",
    "    # ------------------------------\n",
    "    vereda = row[\"vereda\"]\n",
    "\n",
    "    # Solo procesamos si es string\n",
    "    if isinstance(vereda, str):\n",
    "\n",
    "        # Veredas del municipio correcto\n",
    "        df_vereda_filtro = gdf_veredas.loc[gdf_veredas[\"id_municipio\"] == municipio]\n",
    "\n",
    "        # 2A. MATCH EXACTO\n",
    "        filtro = df_vereda_filtro[df_vereda_filtro[\"vereda\"].str.lower() == vereda.lower()]\n",
    "\n",
    "        if len(filtro) > 0:\n",
    "            df_veredas_asociados.at[i, \"vereda\"] = filtro.iloc[0][\"id_vereda\"]\n",
    "            continue\n",
    "\n",
    "        # 2B. FUZZY MATCH SOLO DENTRO DEL MUNICIPIO\n",
    "        lista_veredas = df_vereda_filtro[\"vereda\"].tolist()\n",
    "\n",
    "        if lista_veredas:\n",
    "            mejor_match, score = process.extractOne(vereda, lista_veredas)\n",
    "\n",
    "            if score >= 80:\n",
    "                vereda_id = df_vereda_filtro.loc[\n",
    "                    df_vereda_filtro[\"vereda\"] == mejor_match,\n",
    "                    \"id_vereda\"\n",
    "                ].iloc[0]\n",
    "\n",
    "                df_veredas_asociados.at[i, \"vereda\"] = vereda_id\n",
    "                continue\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # üö´ No match aceptable ‚Üí dejamos el texto original\n",
    "        # ------------------------------------------------------------\n",
    "        print(f\"No hay match v√°lido para '{vereda}', se conserva el texto original.\")\n",
    "        # no se cambia nada\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_veredas_asociados.columns)\n",
    "print(df_municipio.columns)\n",
    "print(df_departamento.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados[\"vereda\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados_georeferenciadas = df_veredas_asociados.loc[~df_veredas_asociados[\"vereda\"].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "df_veredas_asociados_no_georeferenciadas = df_veredas_asociados.loc[df_veredas_asociados[\"vereda\"].apply(lambda x: isinstance(x, str))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados_no_georeferenciadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_veredas_asociados_georeferenciadas.merge(df_departamento[[\"id_vereda\", \"vereda\",\"poligono_vereda\"]], left_on=\"vereda\", right_on=\"id_vereda\", how=\"left\")\n",
    "df_veredas_asociados_georeferenciadas = df_veredas_asociados_georeferenciadas.merge(df_departamento[[\"id_vereda\", \"vereda\",\"poligono_vereda\"]], left_on=\"vereda\", right_on=\"id_vereda\", how=\"left\")\n",
    "df_veredas_asociados_georeferenciadas = df_veredas_asociados_georeferenciadas.drop(columns=[\"id_vereda\"])\n",
    "df_veredas_asociados_georeferenciadas = df_veredas_asociados_georeferenciadas.rename({\"vereda_x\":\"id_vereda\", \"vereda_y\": \"nombre_vereda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados_georeferenciadas = df_veredas_asociados_georeferenciadas.rename(\n",
    "    columns={\n",
    "        \"vereda_x\": \"id_vereda\",\n",
    "        \"vereda_y\": \"nombre_vereda\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados_georeferenciadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veredas_asociados_georeferenciadas[\"poligono_vereda\"] = df_veredas_asociados_georeferenciadas[\"poligono_vereda\"].apply(limpiar_wkt)\n",
    "\n",
    "# 2. Crear el GeoDataFrame\n",
    "gdf_final = gpd.GeoDataFrame(df_veredas_asociados_georeferenciadas, geometry=\"poligono_vereda\", crs=\"EPSG:4326\")\n",
    "\n",
    "gdf_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "veredas_count = []\n",
    "for vereda in gdf_final[\"id_vereda\"].unique():\n",
    "    gdf_filtro = gdf_final.loc[gdf_final[\"id_vereda\"] == vereda]\n",
    "    veredas_count.append({\n",
    "        \"id_vereda\": vereda,\n",
    "        \"nombre_vereda\": gdf_filtro[\"nombre_vereda\"].iloc[0].upper(),\n",
    "        \"numero_asociados\": len(gdf_filtro),\n",
    "        \"geometry\":gdf_filtro[\"poligono_vereda\"].iloc[0]\n",
    "    })\n",
    "\n",
    "gdf_final_veredas = gpd.GeoDataFrame(veredas_count, geometry=\"geometry\", crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_veredas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Copia por seguridad\n",
    "gdf_final = gdf_final_veredas.copy()\n",
    "\n",
    "# Para ir guardando resultados temporales\n",
    "rows_to_add = []\n",
    "\n",
    "# Iterar solo sobre veredas con numero_asociados\n",
    "for idx, row in gdf_final_veredas.iterrows():\n",
    "\n",
    "    geom = row[\"geometry\"]\n",
    "    nombre = row[\"nombre_vereda\"]\n",
    "\n",
    "    # Buscar veredas vecinas\n",
    "    vecinas = gdf_veredas[\n",
    "        (gdf_veredas.geometry.touches(geom)) &\n",
    "        (gdf_veredas[\"vereda\"] != nombre)\n",
    "    ]\n",
    "    vecinas[\"VECINA\"] = \"SI\"\n",
    "    # A√±adir cada vecina como fila nueva\n",
    "    for _, r in vecinas.iterrows():\n",
    "        rows_to_add.append(r)\n",
    "\n",
    "# Convertir a GeoDataFrame\n",
    "gdf_vecinas = gpd.GeoDataFrame(rows_to_add, geometry=\"geometry\", crs=gdf_veredas.crs)\n",
    "gdf_vecinas = gdf_vecinas.drop(columns=[\"poligono_vereda\"])\n",
    "gdf_vecinas = gdf_vecinas.rename(columns={\n",
    "    \"vereda\": \"nombre_vereda\"\n",
    "})\n",
    "\n",
    "# Unir con gdf_final\n",
    "gdf_final_extendido = pd.concat([gdf_final_veredas, gdf_vecinas], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_final_extendido.columns = [\"id_vereda\", \"vereda\", \"geometry\", \"id_municipio\", \"numero_asociados\", \"geometry\", \"VECINA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Crear un filtro para las filas protegidas\n",
    "protegidas = (\n",
    "    (gdf_final_extendido[\"VECINA\"] == \"SI\") |\n",
    "    (gdf_final_extendido[\"numero_asociados\"].notna() & (gdf_final_extendido[\"numero_asociados\"] != 0))\n",
    ")\n",
    "\n",
    "# 2) Separar protegidas y no protegidas\n",
    "gdf_protegidas = gdf_final_extendido[protegidas]\n",
    "gdf_no_protegidas = gdf_final_extendido[~protegidas]\n",
    "\n",
    "# 3) Hacer drop duplicates SOLO en no protegidas\n",
    "gdf_no_protegidas = gdf_no_protegidas.drop_duplicates(subset=\"geometry\")\n",
    "\n",
    "# 4) Volver a unir\n",
    "gdf_final_extendido = pd.concat([gdf_protegidas, gdf_no_protegidas], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in gdf_final_extendido.iterrows():\n",
    "    if not pd.notna(row[\"id_municipio\"]):\n",
    "        df_filtro = df_departamento.loc[df_departamento[\"id_vereda\"] == row[\"id_vereda\"]]\n",
    "        gdf_final_extendido.at[i,\"id_municipio\"]= df_filtro[\"id_municipio\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido[\"municipio\"] = None\n",
    "gdf_final_extendido[\"departamento\"] = None\n",
    "for i, row in gdf_final_extendido.iterrows(): \n",
    "    id_municipio = row[\"id_municipio\"]\n",
    "    nombre = df_municipio[\"municipio\"].loc[df_municipio[\"id_municipio\"] == id_municipio].iloc[0]\n",
    "    departamento = df_municipio[\"departamento\"].loc[df_municipio[\"id_municipio\"] == id_municipio].iloc[0]\n",
    "    print(id_municipio)\n",
    "    print(nombre)\n",
    "    gdf_final_extendido.at[i, \"municipio\"] = nombre\n",
    "    gdf_final_extendido.at[i, \"departamento\"] = departamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtro_asociados = gdf_final_extendido.loc[~gdf_final_extendido[\"numero_asociados\"].isna()]\n",
    "lista_veredas = gdf_filtro_asociados[\"id_vereda\"].to_list()\n",
    "gdf_filtro_vecinos = gdf_final_extendido.loc[gdf_final_extendido[\"numero_asociados\"].isna()]\n",
    "gdf_filtro_vecinos = gdf_filtro_vecinos.loc[~gdf_filtro_vecinos[\"id_vereda\"].isin(lista_veredas)]\n",
    "gdf_final_extendido = gpd.GeoDataFrame(pd.concat([gdf_filtro_asociados, gdf_filtro_vecinos]), geometry=\"geometry\", crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_municipios = gdf_final_extendido[\"id_municipio\"].to_list()\n",
    "lista_veredas = gdf_final_extendido[\"id_vereda\"].to_list()\n",
    "\n",
    "gdf_veredas_faltantes = gdf_veredas.loc[\n",
    "    (~gdf_veredas[\"id_vereda\"].isin(lista_veredas))&\n",
    "    (gdf_veredas[\"id_municipio\"].isin(lista_municipios))\n",
    "]\n",
    "gdf_veredas_faltantes = gdf_veredas_faltantes.rename(columns={\"vereda\":\"nombre_vereda\"})\n",
    "gdf_final_extendido = gpd.GeoDataFrame(pd.concat([gdf_final_extendido, gdf_veredas_faltantes]), geometry=\"geometry\", crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_veredas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido[\"municipio\"] = None\n",
    "gdf_final_extendido[\"departamento\"] = None\n",
    "for i, row in gdf_final_extendido.iterrows(): \n",
    "    id_municipio = row[\"id_municipio\"]\n",
    "    nombre = df_municipio[\"municipio\"].loc[df_municipio[\"id_municipio\"] == id_municipio].iloc[0]\n",
    "    departamento = df_municipio[\"departamento\"].loc[df_municipio[\"id_municipio\"] == id_municipio].iloc[0]\n",
    "    print(id_municipio)\n",
    "    print(nombre)\n",
    "    gdf_final_extendido.at[i, \"municipio\"] = nombre\n",
    "    gdf_final_extendido.at[i, \"departamento\"] = departamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final_extendido.to_file(\"./veredas_influyentes_2.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"Productores por vereda.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    df_veredas_asociados_georeferenciadas.to_excel(\n",
    "        writer, \n",
    "        sheet_name=\"georeferenciadas\", \n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    df_veredas_asociados_no_georeferenciadas.to_excel(\n",
    "        writer, \n",
    "        sheet_name=\"no_georeferenciadas\", \n",
    "        index=False\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
