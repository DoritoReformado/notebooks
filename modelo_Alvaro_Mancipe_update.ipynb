{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "from shapely import wkt\n",
    "from shapely.errors import WKTReadingError\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely import Polygon\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import numpy as np\n",
    "from shapely.validation import make_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\dorito\\Documents\\Levantamiento Asociados mayores de 4 ha faltantes 10 01 2025.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cedulas = df[\"CEDULA\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "login = {\n",
    "    \"username\":\"Dorito\",\n",
    "    \"password\":\"Portador123\"\n",
    "}\n",
    "# Crear una sesión para mantener la cookie\n",
    "session = requests.Session()\n",
    "response = session.post(\"https://192.168.179.3/api/user/login/\", login, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesión para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://192.168.179.3/api/user/login/\", login, verify=False)\n",
    "    datos = []\n",
    "    while url:\n",
    "        response = session.get(url, verify=False)\n",
    "        info = response.json()\n",
    "        datos.extend(info[\"results\"])\n",
    "        url = info[\"next\"]\n",
    "    return datos\n",
    "\n",
    "def get_data_not_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesión para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://192.168.179.3/api/user/login/\", login, verify=False)\n",
    "    response = session.get(url, verify=False)\n",
    "    info = response.json()\n",
    "    return info\n",
    "\n",
    "\n",
    "def parse_geom_safe(wkt_string):\n",
    "    try:\n",
    "        if isinstance(wkt_string, str) and \"SRID=\" in wkt_string:\n",
    "            return wkt.loads(wkt_string.split(\";\", 1)[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None  # simplemente ignora lo inválido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas_mancipe = gpd.read_file(r\"C:\\Users\\dorito\\Downloads\\fincas mancipe 2 nov.geojson\")\n",
    "gdf_lotes_mancipe = gpd.read_file(r\"C:\\Users\\dorito\\Downloads\\Lote Mancipe 2 Nov.geojson\")\n",
    "# gdf_conservacion_mancipe = gpd.read_file(r\"C:\\Users\\dorito\\Documents\\arreglando bd\\Poligonos_Alvaro\\Conservacion.shp\")\n",
    "# gdf_infraestructra_mancipe = gpd.read_file(r\"C:\\Users\\dorito\\Documents\\arreglando bd\\Poligonos_Alvaro\\Infraestructura.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FINCAS ---\n",
    "gdf_fincas_mancipe[\"CEDULA\"] = pd.to_numeric(\n",
    "    gdf_fincas_mancipe[\"CEDULA\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# --- LOTES ---\n",
    "gdf_lotes_mancipe[\"CEDULA\"] = pd.to_numeric(\n",
    "    gdf_lotes_mancipe[\"CEDULA\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas = gdf_fincas_mancipe.loc[gdf_fincas_mancipe[\"CEDULA\"].isin(lista_cedulas)]\n",
    "gdf_lotes = gdf_lotes_mancipe.loc[gdf_lotes_mancipe[\"CEDULA\"].isin(lista_cedulas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes.columns\n",
    "gdf_lotes[\"TIEMPO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas[\"FECHA_ULTIMA_VISITA\"] = (\n",
    "    pd.to_datetime(gdf_fincas[\"FECHA_ULTIMA_VISITA\"], errors='coerce')\n",
    "    .dt.strftime('%Y-%m-%d')\n",
    "    .fillna('')\n",
    ")\n",
    "gdf_lotes[\"TIEMPO\"] = (\n",
    "    pd.to_datetime(gdf_lotes[\"TIEMPO\"], errors='coerce')\n",
    "    .dt.strftime('%Y-%m-%d')\n",
    "    .fillna('')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "def safe_cedula(x, default=1):\n",
    "    \"\"\"Convierte a int si es posible, si no devuelve 1 por defecto.\"\"\"\n",
    "    if pd.isna(x) or str(x).strip() == \"\":\n",
    "        return default\n",
    "    try:\n",
    "        return int(float(x))  # si viene como '12345.0'\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def enviar_poligono(row, session, mongo_atribute, url):\n",
    "    elementos = []  # lo que falla\n",
    "    try:\n",
    "        documento = safe_cedula(row[\"CEDULA\"])\n",
    "        respuesta = {\n",
    "            \"documento_productor\":int(documento),\n",
    "            \"poligono\":str(row[\"geometry\"]),\n",
    "            \"mongo_atribute\": mongo_atribute\n",
    "        }\n",
    "        # petición al servidor\n",
    "        resp = session.post(url, json=respuesta, verify=False)\n",
    "        elementos = {\n",
    "            \"payload\": respuesta,\n",
    "            \"status_code\": resp.status_code,\n",
    "            \"response_text\": resp.text\n",
    "        }\n",
    "    except:\n",
    "        elementos = {\n",
    "            \"payload\": respuesta\n",
    "        }\n",
    "\n",
    "    return elementos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBIDAS = []\n",
    "for i, row in gdf_fincas.iterrows():\n",
    "    if pd.notna(row[\"FECHA_ULTIMA_VISITA\"]) and str(row[\"FECHA_ULTIMA_VISITA\"]).strip() != \"\":\n",
    "        fecha_visita = row[\"FECHA_ULTIMA_VISITA\"]\n",
    "    else:\n",
    "        fecha_visita = \"\"\n",
    "\n",
    "    if pd.notna(row[\"NOMBRE_FINCA\"]) and str(row[\"NOMBRE_FINCA\"]).strip() != \"\":\n",
    "        NOMBRE_FINCA = row[\"NOMBRE_FINCA\"]\n",
    "    else:\n",
    "        NOMBRE_FINCA = \"\"\n",
    "    mongo_atribute = {\n",
    "        \"nombre_finca\": NOMBRE_FINCA,\n",
    "        \"fecha_visita\": fecha_visita\n",
    "    }\n",
    "    elementos = enviar_poligono(row, session, mongo_atribute, \"https://192.168.179.3/api/v1/poligonos_fincas/\")\n",
    "    SUBIDAS.append(elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fincas_subidas = pd.DataFrame(SUBIDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fincas_subidas.to_excel(\"./fincas_subidas_mancipe_octubre.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes[\"COD_LOTE\"] = gdf_lotes[\"COD_LOTE\"].apply(\n",
    "    lambda x: int(str(x).split(\" \")[-1]) if pd.notna(x) and str(x).strip() != \"\" else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar VARIEDAD en mayúsculas\n",
    "gdf_lotes[\"VARIEDAD\"] = gdf_lotes[\"VARIEDAD\"].astype(str).str.upper()\n",
    "\n",
    "# Crear la nueva columna 'variedades' con el valor correcto\n",
    "gdf_lotes[\"variedades\"] = gdf_lotes.apply(\n",
    "    lambda row: row[\"VARIEDAD\"] if pd.isna(row[\"variedades_2\"]) or str(row[\"variedades_2\"]).strip() == \"\" else row[\"variedades_2\"],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes['ESTADO_PYTHON'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes['ESTADO_PYTHON'] = gdf_lotes['ESTADO_PYTHON'].map({\n",
    "    \"produccion\": 1,\n",
    "    \"levante\": 0,\n",
    "    None: 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes[\"SUB_O\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_nan(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: limpiar_nan(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [limpiar_nan(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (math.isnan(obj) or math.isinf(obj)):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "    \n",
    "def safe_int(x, default=0):\n",
    "    \"\"\"Convierte a int si es posible, si no devuelve default.\"\"\"\n",
    "    try:\n",
    "        if pd.notna(x) and str(x).strip() != \"\":\n",
    "            return int(float(x))  # por si viene como '12.0'\n",
    "        else:\n",
    "            return default\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "SUBIDAS = []\n",
    "\n",
    "for i, row in gdf_lotes.iterrows():\n",
    "    if pd.notna(row[\"SUB_O\"]) and str(row[\"SUB_O\"]).strip() != \"\":\n",
    "        subtipo_operacion = int(row[\"SUB_O\"])\n",
    "    else:\n",
    "        subtipo_operacion = 2\n",
    "    mongo_atribute = {\n",
    "        \"fecha_visita\": \"\",\n",
    "        \"observaciones\": \"\",\n",
    "        \"descripcion\": \"\",\n",
    "        \"numero_lote\": safe_int(row[\"COD_LOTE\"]),\n",
    "        \"descripcion_lote\": \"\",\n",
    "        \"variedad\": row[\"variedades\"],\n",
    "        \"distancia_surcos\": safe_int(row[\"D_CALLE\"]),\n",
    "        \"distancia_plantas\": safe_int(row[\"D_PLANTA\"]),\n",
    "        \"densidad\": safe_int(row[\"DENSIDAD\"]),\n",
    "        \"numero_plantas\": safe_int(row[\"ARBOLES\"]),\n",
    "        \"gramos_plantas\": 500,\n",
    "        \"kg_produccion\": safe_int(row[\"ARBOLES\"]) / 2,\n",
    "        \"fecha_actividad\": \"\",\n",
    "        \"produccion\": safe_int(row[\"ESTADO_PYTHON\"]),\n",
    "        \"estado\": \"BUENO\",\n",
    "        \"subtipo_operacion\": subtipo_operacion,\n",
    "    }\n",
    "    \n",
    "    elementos = enviar_poligono(row, session, mongo_atribute, \"https://192.168.179.3/api/v1/poligonos_lotes/\")\n",
    "    SUBIDAS.append(elementos)\n",
    "    # print(mongo_atribute)\n",
    "print(\"Elementos_enviados:\", len(SUBIDAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_lotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lotes_subidos = pd.DataFrame(SUBIDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lotes_subidos.to_excel(\"./lotes_subidos_octubre.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_conservacion_no_solapa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBIDAS = []\n",
    "\n",
    "for i, row in gdf_conservacion_no_solapa.iterrows():\n",
    "    mongo_atribute = {\n",
    "        \"tipo_arbol\": row[\"TIPO_ARBOL\"]\n",
    "    }\n",
    "    mongo_atribute = limpiar_nan(mongo_atribute)\n",
    "    elementos = enviar_poligono(row, session, mongo_atribute, \"https://192.168.179.3/api/v1/poligonos_conservacion/\")\n",
    "    SUBIDAS.append(elementos)\n",
    "    # print(mongo_atribute)\n",
    "print(\"Elementos_enviados:\", len(SUBIDAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_infraestructura_no_solapa.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = [\"VIVIENDA\", \"ESTRUCTURA\", \"TIPO_INSTA\"]\n",
    "\n",
    "gdf_infraestructura_no_solapa[\"INSTALACIONES\"] = gdf_infraestructura_no_solapa[cols].apply(\n",
    "    lambda row: [str(x) for x in row if pd.notna(x) and str(x).strip() != \"\"],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBIDAS = []\n",
    "\n",
    "for i, row in gdf_infraestructura_no_solapa.iterrows():\n",
    "    mongo_atribute = {\n",
    "        \"estructura\": row[\"INSTALACIONES\"]\n",
    "    }\n",
    "    mongo_atribute = limpiar_nan(mongo_atribute)\n",
    "    elementos = enviar_poligono(row, session, mongo_atribute, \"https://192.168.179.3/api/v1/poligonos_infraestructura/\")\n",
    "    SUBIDAS.append(elementos)\n",
    "    # print(mongo_atribute)\n",
    "print(\"Elementos_enviados:\", len(SUBIDAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borrar = pd.DataFrame(SUBIDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borrar.loc[df_borrar[\"status_code\"] != 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fincas_no_solapa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in gdf_fincas_no_solapa.iterrows():\n",
    "    url_base_fincas = \"https://192.168.179.3/api/v1/poligonos_fincas/\"\n",
    "    if not pd.isna(row[\"fecha_visi\"]):\n",
    "        fecha_visita = row[\"fecha_visi\"].strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        fecha_visita = \"\"\n",
    "    \n",
    "    if not pd.isna(row[\"documento\"]):\n",
    "        documento = int(float(row[\"documento\"]))\n",
    "    else:\n",
    "        documento = 1\n",
    "\n",
    "    respuesta_postgres = {\n",
    "        \"poligono\": str(row[\"geometry\"]),\n",
    "        \"documento_productor\": documento \n",
    "    }\n",
    "\n",
    "    respuesta_atributos = {\n",
    "        \"fecha_visita\": fecha_visita,\n",
    "        \"nombre_finca\": row[\"nombre_fin\"],\n",
    "        \"descripcion\": row[\"descripcio\"]\n",
    "    }\n",
    "    if row[\"id\"] == '1' or row[\"id\"] == 1:\n",
    "        respuesta_postgres[\"mongo_atribute\"] = respuesta_atributos\n",
    "        session.post(url=url_base_fincas, json=respuesta_postgres, verify=False)\n",
    "    else:\n",
    "        id_pol = row[\"id\"]\n",
    "        url_base_fincas_postgres = f\"{url_base_fincas}{id_pol}/\"\n",
    "        session.patch(url_base_fincas_postgres, json=respuesta_postgres, verify=False)\n",
    "        fecha_actual = datetime.now().strftime(\"%d-%m-%Y_00--00--00\")\n",
    "        url_base_fincas_mongo = f\"{url_base_fincas}update/mongo_update/{id_pol}/{fecha_actual}/\"\n",
    "        mongo_atributes_json = {\n",
    "            \"mongo_atribute\": respuesta_atributos\n",
    "        }\n",
    "        session.post(url_base_fincas_mongo, json=respuesta_postgres, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lotes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in gdf_lotes.iterrows():\n",
    "    url_base_fincas = \"https://192.168.179.3/api/v1/poligonos_lotes/\"\n",
    "    if not pd.isna(row[\"fecha_visi\"]):\n",
    "        fecha_visita = row[\"fecha_visi\"].strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        fecha_visita = \"\"\n",
    "\n",
    "    if not pd.isna(row[\"fecha_acti\"]):\n",
    "        fecha_actividad = row[\"fecha_acti\"].strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        fecha_actividad = \"\"\n",
    "\n",
    "\n",
    "    if not pd.isna(row[\"documento\"]):\n",
    "        documento = int(float(row[\"documento\"]))\n",
    "    else:\n",
    "        documento = 1\n",
    "\n",
    "    respuesta_postgres = {\n",
    "        \"poligono\": str(row[\"geometry\"]),\n",
    "        \"documento_productor\": documento \n",
    "    }\n",
    "\n",
    "    respuesta_atributos = {\n",
    "        \"numero_documento\": str(row[\"documento\"]),\n",
    "        \"nombre_productor\": str(row['nom_prod']),\n",
    "        \"fecha_visita\": fecha_visita,\n",
    "        \"area\": safe_int(row['area']),\n",
    "        \"observaciones\": \"\",\n",
    "        \"descripcion\": \"\",\n",
    "        \"numero_lote\": None,\n",
    "        \"descripcion_lote\": \"\",\n",
    "        \"variedad\": row['variedad'],\n",
    "        \"distancia_surcos\": safe_int(row['distancia_']),\n",
    "        \"distancia_plantas\": safe_int(row['distanci_1']),\n",
    "        \"densidad\": safe_int(row['densidad']),\n",
    "        \"numero_plantas\": safe_int(row['numero_pla']),\n",
    "        \"gramos_plantas\": safe_int(row['gramos_pla']),\n",
    "        \"kg_produccion\": safe_int(row['kg_producc']),\n",
    "        \"fecha_actividad\": fecha_actividad,\n",
    "        \"produccion\": row['produccion'],\n",
    "        \"estado_cultivo\": row.get('estado_cul') if 'estado_cul' in row and pd.notnull(row['estado_cul']) else None,\n",
    "        \"subtipo_operacion\": row['subtipo_op']\n",
    "    }\n",
    "    if row[\"id\"] == '1' or row[\"id\"] == 1:\n",
    "        respuesta_postgres[\"mongo_atribute\"] = respuesta_atributos\n",
    "        session.post(url=url_base_fincas, json=respuesta_postgres, verify=False)\n",
    "    else:\n",
    "        id_pol = row[\"id\"]\n",
    "        url_base_fincas_postgres = f\"{url_base_fincas}{id_pol}/\"\n",
    "        session.patch(url_base_fincas_postgres, json=respuesta_postgres, verify=False)\n",
    "        fecha_actual = datetime.now().strftime(\"%d-%m-%Y_00--00--00\")\n",
    "        url_base_fincas_mongo = f\"{url_base_fincas}update/mongo_update/{id_pol}/{fecha_actual}/\"\n",
    "        mongo_atributes_json = {\n",
    "            \"mongo_atribute\": respuesta_atributos\n",
    "        }\n",
    "        session.post(url_base_fincas_mongo, json=respuesta_postgres, verify=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
