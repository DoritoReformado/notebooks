{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "from shapely import wkt\n",
    "from shapely.errors import WKTReadingError\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely import Polygon\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_safe(x):\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "login = {\n",
    "    \"username\":\"Dorito\",\n",
    "    \"password\":\"Portador123\"\n",
    "}\n",
    "# Crear una sesión para mantener la cookie\n",
    "session = requests.Session()\n",
    "response = session.post(\"https://produccion.local/api/user/login/\", login, verify=False)\n",
    "def get_data_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesión para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://produccion.local/api/user/login/\", login, verify=False)\n",
    "    datos = []\n",
    "    while url:\n",
    "        response = session.get(url, verify=False)\n",
    "        info = response.json()\n",
    "        datos.extend(info[\"results\"])\n",
    "        url = info[\"next\"]\n",
    "    return datos\n",
    "\n",
    "def get_data_not_paginated(url):\n",
    "    login = {\n",
    "        \"username\":\"Dorito\",\n",
    "        \"password\":\"Portador123\"\n",
    "    }\n",
    "    # Crear una sesión para mantener la cookie\n",
    "    session = requests.Session()\n",
    "    response = session.post(\"https://produccion.local/api/user/login/\", login, verify=False)\n",
    "    response = session.get(url, verify=False)\n",
    "    info = response.json()\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_productor = \"https://produccion.local/api/v1/productor/\"\n",
    "url_productor_data = \"https://produccion.local/api/v1/productor/mongo_get/productor_data/\"\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor = get_data_not_paginated(url_productor)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor_data = get_data_not_paginated(url_productor_data)\n",
    "df_productor = pd.json_normalize(datos_productor)\n",
    "df_productor_data = pd.json_normalize(datos_productor_data)\n",
    "df_productor = df_productor.merge(\n",
    "    df_productor_data,\n",
    "    left_on=\"productor_data\",\n",
    "    right_on=\"_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df_productor.to_excel(\"./productores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y normalizar datos\n",
    "url = \"https://produccion.local/api/v1/poligonos_lotes/\"\n",
    "url_productor = \"https://produccion.local/api/v1/productor/\"\n",
    "url_productor_data = \"https://produccion.local/api/v1/productor/mongo_get/productor_data/\"\n",
    "url_fincas = \"https://produccion.local/api/v1/poligonos_fincas/\"\n",
    "url_municipio = \"https://produccion.local/api/v1/municipio/\"\n",
    "url_departamento = \"https://produccion.local/api/v1/vereda/\"\n",
    "url_lotes = \"https://produccion.local/api/v1/poligonos_lotes/mongo_get/mongo_atribute/\"\n",
    "print(\"cargando datos lotes\")\n",
    "datos = get_data_paginated(url)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor = get_data_not_paginated(url_productor)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor_data = get_data_not_paginated(url_productor_data)\n",
    "print(\"cargando datos fincas\")\n",
    "datos_fincas = get_data_paginated(url_fincas)\n",
    "print(\"cargando datos lotes\")\n",
    "datos_lotes = get_data_not_paginated(url_lotes)\n",
    "print(\"Cargando datos municipios\")\n",
    "datos_municipios = get_data_not_paginated(url_municipio)\n",
    "print(\"cargando datos departamentos\")\n",
    "datos_departamentos = get_data_not_paginated(url_departamento)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.json_normalize(datos)\n",
    "df_productor = pd.json_normalize(datos_productor)\n",
    "df_productor_data = pd.json_normalize(datos_productor_data)\n",
    "df_fincas = pd.json_normalize(datos_fincas)\n",
    "df_lotes = pd.json_normalize(datos_lotes)\n",
    "df_municipio = pd.json_normalize(datos_municipios)\n",
    "df_departamento = pd.json_normalize(datos_departamentos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar productores que tienen postgres_data.id\n",
    "df_productor = df_productor[df_productor[\"id\"].notna()]\n",
    "# Realizar los merge sin eliminar filas del DataFrame principal\n",
    "df_completo = df.merge(\n",
    "    df_productor,\n",
    "    left_on=\"productor\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_productor_data,\n",
    "    left_on=\"productor_data\",\n",
    "    right_on=\"_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_fincas,\n",
    "    left_on=\"finca\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_lotes,\n",
    "    left_on=\"id_x\",\n",
    "    right_on=\"poligono_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ejemplo: renombrar id en municipio y departamento\n",
    "df_municipio = df_municipio.rename(columns={\"id\": \"id_municipio\"})\n",
    "df_departamento = df_departamento.rename(columns={\"id\": \"id_departamento\"})\n",
    "df_departamento = df_departamento.rename(columns={\"municipio\": \"alkdsjflkajsñldkfjasdl\"})\n",
    "\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_municipio,\n",
    "    left_on=\"municipio_x\",\n",
    "    right_on=\"id_municipio\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_completo = df_completo.merge(\n",
    "    df_departamento,\n",
    "    left_on=\"vereda_x\",\n",
    "    right_on=\"id_departamento\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el GeoDataFrame (con geometrías inválidas como None)\n",
    "\n",
    "def parse_geom_safe(wkt_string):\n",
    "    try:\n",
    "        if isinstance(wkt_string, str) and \"SRID=\" in wkt_string:\n",
    "            return wkt.loads(wkt_string.split(\";\", 1)[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None  # simplemente ignora lo inválido\n",
    "\n",
    "# Aplicar solo a las válidas\n",
    "df_completo[\"geometry\"] = df_completo[\"poligono_x\"].apply(parse_geom_safe)\n",
    "\n",
    "# Crear el GeoDataFrame sin que explote\n",
    "gdf = gpd.GeoDataFrame(df_completo, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Validación de cantidad\n",
    "# assert len(gdf) == 10530, f\"Se esperaban 10530 registros, pero hay {len(gdf)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import unary_union\n",
    "lista_de_necesarios = [83239477, 55056272, 1082155195]\n",
    "respuesta = []\n",
    "for documento in lista_de_necesarios:\n",
    "    gdf_filtro = gdf.loc[gdf[\"postgres_data.documento\"] == documento]\n",
    "    poligono = unary_union(gdf_filtro.geometry)\n",
    "    centroide = poligono.centroid\n",
    "    respuesta.append({\n",
    "        \"documento\": documento,\n",
    "        \"nombre\": gdf_filtro[\"datos.nombre_completo\"].iloc[0],\n",
    "        \"codigo_productor\": gdf_filtro[\"codigo_productor\"].iloc[0],\n",
    "        \"codigo_finca\": gdf_filtro[\"codigo_finca\"].iloc[0],\n",
    "        \"latitud\": centroide.y,\n",
    "        \"longitud\": centroide.x,\n",
    "        \"geometry\": poligono\n",
    "    })\n",
    "gdf_final = gpd.GeoDataFrame(pd.DataFrame(respuesta), geometry=\"geometry\", crs=4326)\n",
    "gdf_final.to_file(\"./Poligonos_Faltante_CP_12_DICIEMBRE.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"datos.produccion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"datos.categoria\"] = gdf[\"datos.categoria\"].fillna('Qfield')\n",
    "gdf[\"datos.produccion\"] = gdf[\"datos.produccion\"].fillna(0)\n",
    "gdf[\"datos.produccion\"] = gdf[\"datos.produccion\"].isin([1, \"Produccion\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"datos.categoria\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.validation import make_valid\n",
    "\n",
    "def filtrar_poligonos_superpuestos(gdf, umbral=0.85):\n",
    "    # Asegurar que la fecha sea datetime\n",
    "    gdf = gdf.copy()\n",
    "    gdf[\"fecha\"] = pd.to_datetime(gdf[\"fecha\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "    # Ordenar por fecha descendente (primero los más recientes)\n",
    "    gdf = gdf.sort_values(by=\"fecha\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Lista de índices que queremos conservar\n",
    "    indices_validos = []\n",
    "\n",
    "    for i, row_i in gdf.iterrows():\n",
    "        geom_i = row_i.geometry\n",
    "        area_i = geom_i.area\n",
    "        keep = True\n",
    "\n",
    "        for j in indices_validos:\n",
    "            geom_j = gdf.loc[j, \"geometry\"]\n",
    "            area_j = geom_j.area\n",
    "\n",
    "            inter = geom_i.intersection(geom_j).area\n",
    "            if inter > 0:\n",
    "                # calcular porcentaje de solapamiento respecto al polígono más pequeño\n",
    "                overlap = inter / min(area_i, area_j)\n",
    "                if overlap >= umbral:\n",
    "                    keep = False\n",
    "                    break\n",
    "\n",
    "        if keep:\n",
    "            indices_validos.append(i)\n",
    "\n",
    "    return gdf.loc[indices_validos].reset_index(drop=True)\n",
    "def filtrar_poligonos_priorizar_pequenos(gdf, umbral=0.01):\n",
    "    gdf = gdf.copy()\n",
    "\n",
    "    # Reparar geometrías\n",
    "    gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda g: make_valid(g))\n",
    "\n",
    "    # Calcular áreas\n",
    "    gdf[\"area\"] = gdf.geometry.area\n",
    "\n",
    "    # Pequeños primero\n",
    "    gdf = gdf.sort_values(\"area\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    indices_validos = []\n",
    "\n",
    "    for i, row_i in gdf.iterrows():\n",
    "        geom_i = row_i.geometry\n",
    "        area_i = row_i.area\n",
    "\n",
    "        keep = True\n",
    "        \n",
    "        # Comparar con los ya aceptados (que son pequeños o iguales)\n",
    "        for j in indices_validos:\n",
    "            geom_j = gdf.loc[j, \"geometry\"]\n",
    "            area_j = gdf.loc[j, \"area\"]\n",
    "\n",
    "            # No necesitamos verificar el caso contrario: j siempre es pequeño o igual\n",
    "            inter = geom_i.intersection(geom_j).area\n",
    "            if inter > 0:\n",
    "                overlap = inter / min(area_i, area_j)\n",
    "                if overlap >= umbral:\n",
    "                    # geom_i (que es más grande o igual) se elimina\n",
    "                    keep = False\n",
    "                    break\n",
    "        \n",
    "        if keep:\n",
    "            indices_validos.append(i)\n",
    "\n",
    "    return gdf.loc[indices_validos].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['datos.fecha_actividad'] = pd.to_datetime(gdf['datos.fecha_actividad'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"datos.gramos_plantas\"] = gdf[\"datos.gramos_plantas\"].fillna(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"datos.numero_plantas\"] = pd.to_numeric(gdf[\"datos.numero_plantas\"], errors=\"coerce\")\n",
    "gdf[\"datos.gramos_plantas\"] = pd.to_numeric(gdf[\"datos.gramos_plantas\"], errors=\"coerce\")\n",
    "\n",
    "gdf[\"datos.kg_produccion\"] = gdf[\"datos.numero_plantas\"] * (gdf[\"datos.gramos_plantas\"] / 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelo Basado en Municipios\n",
    "\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "\n",
    "# # Crear un DataFrame vacío para almacenar los resultados\n",
    "# resultados = []\n",
    "# def calcular_reportes(gdf):\n",
    "#     # asegurar conversión\n",
    "#     gdf[\"datos.numero_plantas\"] = pd.to_numeric(gdf[\"datos.numero_plantas\"], errors=\"coerce\")\n",
    "#     gdf[\"area_x\"] = pd.to_numeric(gdf[\"area_x\"], errors=\"coerce\")\n",
    "\n",
    "#     respuesta = {}\n",
    "#     respuesta[\"municipio\"] = gdf[\"municipio\"].iloc[0] if not gdf.empty else \"\"\n",
    "#     respuesta[\"departamento\"] = gdf[\"departamento\"].iloc[0] if not gdf.empty else \"\"\n",
    "    \n",
    "#     # for categoria in gdf[\"datos.categoria\"].unique():   # <- mejor unique()\n",
    "#     #     gdf_categoria = gdf.loc[gdf[\"datos.categoria\"] == categoria]\n",
    "#     #     gdf_categoria_produccion = gdf_categoria.loc[gdf_categoria[\"datos.produccion\"]]\n",
    "#     #     gdf_categoria_levante = gdf_categoria.loc[~gdf_categoria[\"datos.produccion\"]]\n",
    "#     #     respuesta[f\"{categoria}_area_levante\"] = gdf_categoria_levante[\"area_x\"].sum()\n",
    "#     #     respuesta[f\"{categoria}_plantas_levante\"] = gdf_categoria_levante[\"datos.numero_plantas\"].sum()\n",
    "#     #     respuesta[f\"{categoria}_area_produccion\"] = gdf_categoria_produccion[\"area_x\"].sum()\n",
    "#     #     respuesta[f\"{categoria}_plantas_produccion\"] = gdf_categoria_produccion[\"datos.numero_plantas\"].sum()\n",
    "    \n",
    "#     gdf_categoria_final = gdf\n",
    "#     gdf_categoria_produccion = gdf_categoria_final.loc[gdf_categoria_final[\"datos.produccion\"]]\n",
    "#     gdf_categoria_levante = gdf_categoria_final.loc[~gdf_categoria_final[\"datos.produccion\"]]\n",
    "#     respuesta[\"area_levante\"] = gdf_categoria_levante[\"area_x\"].sum()\n",
    "#     respuesta[\"plantas_levante\"] = gdf_categoria_levante[\"datos.numero_plantas\"].sum()\n",
    "#     respuesta[\"area_produccion\"] = gdf_categoria_produccion[\"area_x\"].sum()\n",
    "#     respuesta[\"plantas_produccion\"] = gdf_categoria_produccion[\"datos.numero_plantas\"].sum()\n",
    "#     respuesta[\"fecha_actividad_promedio\"] = gdf_categoria_produccion[\"datos.fecha_actividad\"].mean()\n",
    "#     respuesta[\"densidad_promedio\"] = gdf_categoria_final[\"datos.densidad\"].mean()\n",
    "#     respuesta[\"kg_produccion\"] = gdf_categoria_produccion[\"datos.kg_produccion\"].sum()\n",
    "#     respuesta[\"kg_levante\"] = gdf_categoria_levante[\"datos.kg_produccion\"].sum()\n",
    "\n",
    "#     return respuesta\n",
    "\n",
    "\n",
    "# # gdf = filtrar_poligonos_superpuestos(gdf, umbral=0.85)\n",
    "\n",
    "# for documento in gdf[\"municipio\"].unique():\n",
    "#     print(documento)\n",
    "#     gdf_productor = gdf.loc[gdf[\"municipio\"] == documento]\n",
    "#     gdf_productor = gdf_productor.loc[~gdf_productor[\"geometry\"].isna()]\n",
    "#     resultados.append(calcular_reportes(gdf_productor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los resultados\n",
    "resultados = []\n",
    "def calcular_reportes(gdf):\n",
    "    # asegurar conversión\n",
    "    gdf[\"datos.numero_plantas\"] = pd.to_numeric(gdf[\"datos.numero_plantas\"], errors=\"coerce\")\n",
    "    gdf[\"area_x\"] = pd.to_numeric(gdf[\"area_x\"], errors=\"coerce\")\n",
    "\n",
    "    respuesta = {}\n",
    "    respuesta[\"documento\"] = gdf[\"documento\"].iloc[0] if not gdf.empty else \"\"\n",
    "    respuesta[\"nombre\"] = gdf[\"datos.nombre_completo\"].iloc[0] if not gdf.empty else \"\"\n",
    "    respuesta[\"codigo_productor\"] = gdf[\"codigo_productor\"].iloc[0] if not gdf.empty else \"\"\n",
    "    \n",
    "    # for categoria in gdf[\"datos.categoria\"].unique():   # <- mejor unique()\n",
    "    #     gdf_categoria = gdf.loc[gdf[\"datos.categoria\"] == categoria]\n",
    "    #     gdf_categoria_produccion = gdf_categoria.loc[gdf_categoria[\"datos.produccion\"]]\n",
    "    #     gdf_categoria_levante = gdf_categoria.loc[~gdf_categoria[\"datos.produccion\"]]\n",
    "    #     respuesta[f\"{categoria}_area_levante\"] = gdf_categoria_levante[\"area_x\"].sum()\n",
    "    #     respuesta[f\"{categoria}_plantas_levante\"] = gdf_categoria_levante[\"datos.numero_plantas\"].sum()\n",
    "    #     respuesta[f\"{categoria}_area_produccion\"] = gdf_categoria_produccion[\"area_x\"].sum()\n",
    "    #     respuesta[f\"{categoria}_plantas_produccion\"] = gdf_categoria_produccion[\"datos.numero_plantas\"].sum()\n",
    "    \n",
    "    gdf_categoria_final = gdf\n",
    "    gdf_categoria_produccion = gdf_categoria_final.loc[gdf_categoria_final[\"datos.produccion\"]]\n",
    "    gdf_categoria_levante = gdf_categoria_final.loc[~gdf_categoria_final[\"datos.produccion\"]]\n",
    "    respuesta[\"area_levante\"] = gdf_categoria_levante[\"area_x\"].sum()\n",
    "    respuesta[\"plantas_levante\"] = gdf_categoria_levante[\"datos.numero_plantas\"].sum()\n",
    "    respuesta[\"area_produccion\"] = gdf_categoria_produccion[\"area_x\"].sum()\n",
    "    respuesta[\"plantas_produccion\"] = gdf_categoria_produccion[\"datos.numero_plantas\"].sum()\n",
    "    respuesta[\"densidad_promedio\"] = gdf_categoria_produccion[\"datos.densidad\"].mean()\n",
    "    respuesta[\"fecha_actividad_promedio\"] = gdf_categoria_produccion[\"datos.fecha_actividad\"].mean()\n",
    "    return respuesta\n",
    "\n",
    "\n",
    "\n",
    "for documento in gdf[\"documento\"].unique():\n",
    "    gdf_productor = gdf.loc[gdf[\"documento\"] == documento]\n",
    "    gdf_productor = gdf_productor.loc[~gdf_productor[\"geometry\"].isna()]\n",
    "    gdf_limpio = filtrar_poligonos_superpuestos(gdf_productor, umbral=0.85)\n",
    "    resultados.append(calcular_reportes(gdf_limpio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [17615621, 1077868357, 4888454, 4939216, 14191767, 83058202, 4911887, 4946046, 83239477, 83055844, 4633378, 12188324, 12190707, 83181887, 83183128, 4939015, 1081517021, 12186723, 1081515806, 93348205, 4939337, 4925846, 10539656, 83240125, 12192355, 12205276, 1080932294, 26575053, 14256994, 79397128, 1080361312, 83056611, 55056272, 79749725, 55059937, 12192720, 12208197, 14212934, 83165054, 26541132, 12365043, 83182724, 4939287, 83058867, 1126001183, 1080364946, 1077873948, 4940702, 83258281, 1080360916, 1082127141, 4900850, 4881181, 83058107, 12196217, 1080182506, 1110538441, 26575324, 1080363194, 1077848393, 12196895, 1082126268, 12202435, 12188249]\n",
    "# df = df.loc[~df[\"documento\"].isin(ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "<h3>Ahora vamos con las fincas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y normalizar datos\n",
    "url = \"https://produccion.local/api/v1/poligonos_fincas/\"\n",
    "url_productor = \"https://produccion.local/api/v1/productor/\"\n",
    "\n",
    "print(\"cargando datos fincas\")\n",
    "datos = get_data_paginated(url)\n",
    "print(\"cargando datos productor\")\n",
    "datos_productor = get_data_not_paginated(url_productor)\n",
    "\n",
    "df_2 = pd.json_normalize(datos)\n",
    "df_productor = pd.json_normalize(datos_productor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar productores que tienen postgres_data.id\n",
    "df_productor = df_productor[df_productor[\"id\"].notna()]\n",
    "# Realizar los merge sin eliminar filas del DataFrame principal\n",
    "df_completo = df_2.merge(\n",
    "    df_productor,\n",
    "    left_on=\"productor\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df_completo = df_completo.merge(\n",
    "    df_municipio,\n",
    "    left_on=\"municipio\",\n",
    "    right_on=\"id_municipio\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el GeoDataFrame (con geometrías inválidas como None)\n",
    "\n",
    "def parse_geom_safe(wkt_string):\n",
    "    try:\n",
    "        if isinstance(wkt_string, str) and \"SRID=\" in wkt_string:\n",
    "            return wkt.loads(wkt_string.split(\";\", 1)[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None  # simplemente ignora lo inválido\n",
    "\n",
    "# Aplicar solo a las válidas\n",
    "df_completo[\"geometry\"] = df_completo[\"poligono\"].apply(parse_geom_safe)\n",
    "\n",
    "# Crear el GeoDataFrame sin que explote\n",
    "gdf = gpd.GeoDataFrame(df_completo, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# from shapely.ops import unary_union\n",
    "# from shapely.validation import make_valid\n",
    "\n",
    "# # Crear columnas nuevas\n",
    "# df[\"Area_Finca\"] = None\n",
    "# df[\"codigo_finca_corregido\"] = None\n",
    "# errores = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     print(f\"{i+1}/{len(df)}\")\n",
    "#     municipio = str(row[\"municipio\"]).strip()\n",
    "\n",
    "#     # Filtrar el gdf por municipio\n",
    "#     gdf_filtro = gdf.loc[gdf[\"municipio_y\"] == municipio].copy()\n",
    "#     if gdf_filtro.empty:\n",
    "#         errores.append((municipio, \"Sin geometrías\"))\n",
    "#         continue\n",
    "\n",
    "#     # Reproyectar\n",
    "#     gdf_filtro = gdf_filtro.to_crs(3116)\n",
    "\n",
    "#     # --- Validar y corregir geometrías ---\n",
    "#     gdf_filtro[\"geometry\"] = gdf_filtro[\"geometry\"].apply(\n",
    "#         lambda geom: make_valid(geom) if geom and not geom.is_valid else geom\n",
    "#     )\n",
    "\n",
    "#     # Algunos \"make_valid\" devuelven colecciones, extrae solo polígonos válidos\n",
    "#     gdf_filtro[\"geometry\"] = gdf_filtro[\"geometry\"].apply(\n",
    "#         lambda geom: geom.geoms[0] if hasattr(geom, \"geoms\") else geom\n",
    "#     )\n",
    "\n",
    "#     # --- Calcular área ---\n",
    "#     try:\n",
    "#         poligono = unary_union(gdf_filtro.geometry)\n",
    "#         area_ha = poligono.area / 10000  # a hectáreas\n",
    "#         df.at[i, \"Area_Finca\"] = area_ha\n",
    "#     except Exception as e:\n",
    "#         errores.append((municipio, str(e)))\n",
    "#         print(f\"⚠️ Error en {municipio}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"./analisis_por_municipio.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Creamos nuevas columnas\n",
    "df[\"Area Finca\"] = None\n",
    "df[\"codigo_finca_corregido\"] = None\n",
    "errores = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(f\"{i+1}/{len(df)}\")\n",
    "    documento = str(row[\"documento\"]).strip()\n",
    "\n",
    "    # Filtrar el gdf por documento\n",
    "    gdf_filtro = gdf.loc[gdf[\"documento\"] == row[\"documento\"]]\n",
    "\n",
    "    if not gdf_filtro.empty:\n",
    "        codigo_fincas = str(gdf_filtro[\"codigo_finca\"].unique()[0]).strip()\n",
    "\n",
    "        # --- Validación del código ---\n",
    "        # Extraer 3 últimos dígitos del documento\n",
    "        ultimos_doc = documento[-3:] if documento.isdigit() else None\n",
    "\n",
    "        # Buscar si el cuarto, tercer y segundo carácter desde el final son números\n",
    "        sufijo = codigo_fincas[-7:-4]  # son los XXX si existen\n",
    "        try:\n",
    "            sufijo = int(sufijo)\n",
    "        except:\n",
    "            sufijo = \"ERROR\"\n",
    "        if sufijo == \"ERROR\":\n",
    "            # El código es inválido → corregir\n",
    "            ultimos_4 = codigo_fincas[-4:]\n",
    "            prefijo = codigo_fincas[:-4]\n",
    "            codigo_corregido = prefijo+str(int(row[\"documento\"]))[-3:]+ultimos_4\n",
    "            df.at[i, \"codigo_finca_corregido\"] = codigo_corregido\n",
    "            errores.append({\n",
    "                \"indice\": i,\n",
    "                \"documento\": documento,\n",
    "                \"codigo_original\": codigo_fincas,\n",
    "                \"codigo_corregido\": codigo_corregido\n",
    "            })\n",
    "        else:\n",
    "            # Código válido, lo dejamos igual\n",
    "            df.at[i, \"codigo_finca_corregido\"] = codigo_fincas\n",
    "\n",
    "        # --- Calcular área ---\n",
    "        gdf_filtro = gdf_filtro.to_crs(3116)\n",
    "        poligono = unary_union(gdf_filtro.geometry)\n",
    "        area_ha = poligono.area / 10000\n",
    "        df.at[i, \"Area Finca\"] = area_ha\n",
    "\n",
    "    else:\n",
    "        # Caso donde no hay finca en gdf\n",
    "        codigo_productor = row[\"codigo_productor\"]\n",
    "        ultimos_doc = documento[-3:] if documento.isdigit() else \"000\"\n",
    "        codigo_fincas = codigo_productor.replace(\"PR\", \"FN\") + ultimos_doc + \"QFL1\"\n",
    "\n",
    "        df.at[i, \"codigo_finca_corregido\"] = codigo_fincas\n",
    "        df.at[i, \"Area Finca\"] = 0\n",
    "\n",
    "# Mostrar resumen de casos erróneos\n",
    "df_errores = pd.DataFrame(errores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fecha_hoy = datetime.now()\n",
    "fecha_hoy_string = fecha_hoy.strftime(\"%d%m%Y\")\n",
    "# print(fecha_hoy_string)\n",
    "df.to_excel(f\"./Inf_Poligonal_{fecha_hoy_string}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ibarra = df.loc[df[\"documento\"].isin([26441476, 26491773, 12208646, 31922655, 83226660, 26575321, 36294651, 83166252, 83212381, 1082124955, 1077856601, 1083924601, 1006093686, 1081515494])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ibarra.to_excel(\"./aso_nuevos_resultado_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[\"datos.variedad\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
