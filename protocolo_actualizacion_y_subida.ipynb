{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Debemos primero crear un diccionario que apunte a los links o rutas que se emplean para subir la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = r\"C:\\Users\\dorito\\OneDrive - Coocentral\\Reportes Qfield\\2. ADRIAN OSPINA RIOS\\2908\"\n",
    "folder_individuales = os.path.join(folder_base, \"shp_individuales\")\n",
    "folder_agrupados = os.path.join(folder_base, \"shp_agrupados\")\n",
    "url_base = \"https://192.168.179.3/\"\n",
    "capas_gdf_dict = {\n",
    "    \"Finca.shp\": f\"{url_base}api/v1/poligonos_fincas/\",\n",
    "    \"Lote.shp\": f\"{url_base}api/v1/poligonos_lotes/\",\n",
    "    \"Construcciones.shp\": f\"{url_base}api/v1/poligonos_infraestructura/\",\n",
    "    \"Conservacion.shp\": f\"{url_base}api/v1/poligonos_conservacion/\"\n",
    "}\n",
    "capas_gdf_dict_agrupados = {\n",
    "    \"Fincas.shp\": f\"{url_base}api/v1/poligonos_fincas/\",\n",
    "    \"Lotes_Mancipe.shp\": f\"{url_base}api/v1/poligonos_lotes/\",\n",
    "    \"Lotes_Otros.shp\": f\"{url_base}api/v1/poligonos_lotes/\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "login = {\n",
    "    \"username\":\"Dorito\",\n",
    "    \"password\":\"Portador123\"\n",
    "}\n",
    "# Crear una sesi√≥n para mantener la cookie\n",
    "session = requests.Session()\n",
    "response = session.post(f\"{url_base}api/user/login/\", login, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_individuales = [(archivo, os.path.join(folder_individuales, archivo))for archivo in os.listdir(folder_individuales) if archivo.endswith(\".shp\")]\n",
    "files_agrupados = [(archivo, os.path.join(folder_agrupados, archivo))for archivo in os.listdir(folder_agrupados) if archivo.endswith(\".shp\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_nan(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: limpiar_nan(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [limpiar_nan(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (math.isnan(obj) or math.isinf(obj)):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "    \n",
    "\n",
    "def reportar_lotes(row):\n",
    "    if pd.notna(row[\"doc_aso\"]):\n",
    "        documento = int(row[\"doc_aso\"])\n",
    "    elif pd.notna(row[\"doc_prod\"]):\n",
    "        documento = int(row[\"doc_prod\"])\n",
    "    else:\n",
    "        documento = None\n",
    "    response = {\n",
    "        \"documento_productor\":documento,\n",
    "        \"poligono\":str(row[\"geometry\"]),\n",
    "        \"mongo_atribute\":{\n",
    "            \"numero_documento\": str(documento),\n",
    "            \"nombre_productor\": str(row['nom_prod']),\n",
    "            \"fecha_visita\": pd.to_datetime(row['fecha_vis']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_vis']) else None,\n",
    "            \"area\": row['area'],\n",
    "            \"observaciones\": \"\",\n",
    "            \"descripcion\": \"\",\n",
    "            \"numero_lote\": row['num_Lote'],\n",
    "            \"descripcion_lote\": \"\",\n",
    "            \"variedad\": row['variedad'],\n",
    "            \"distancia_surcos\": row['dist_surco'],\n",
    "            \"distancia_plantas\": row['dist_plant'],\n",
    "            \"densidad\": row['densidad'],\n",
    "            \"numero_plantas\": row['num_planta'],\n",
    "            \"gramos_plantas\": row['gr_plant'],\n",
    "            \"kg_produccion\": row['kg_produc'],\n",
    "            \"fecha_actividad\": pd.to_datetime(row['fecha_acti']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_acti']) else None,\n",
    "            \"produccion\": row['produccion'],\n",
    "            \"estado_cultivo\":row['estado_cul'],\n",
    "            \"subtipo_operacion\": row['subtipo_op']\n",
    "        }\n",
    "    }\n",
    "    response = limpiar_nan(response)\n",
    "    return response\n",
    "\n",
    "def reportar_fincas(row):\n",
    "    if bool(row['Asociado']):\n",
    "        if not pd.isna(row[\"doc_prod\"]):\n",
    "            documento= int(row[\"doc_prod\"])\n",
    "        else:\n",
    "            documento=None\n",
    "    else:\n",
    "        if not pd.isna(row[\"doc_aso\"]):\n",
    "            documento= int(row[\"doc_aso\"])\n",
    "        else:\n",
    "            documento=None\n",
    "    response = {\n",
    "        \"documento_productor\":documento,\n",
    "        \"poligono\":str(row[\"geometry\"]),\n",
    "        \"mongo_atribute\":{\n",
    "            \"documento\":str(documento),\n",
    "            \"nombre_productor\":str(row[\"nom_prod\"]),\n",
    "            \"area\": row['area'],\n",
    "            \"nombre_finca\": row['nomb_fin'],\n",
    "            \"fecha_visita\": pd.to_datetime(row['fecha_vis']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_vis']) else None\n",
    "        }\n",
    "    }\n",
    "    response = limpiar_nan(response)\n",
    "    return response\n",
    "\n",
    "def reportar_conservacion(row):\n",
    "    if pd.notna(row[\"doc_aso\"]):\n",
    "        documento = int(row[\"doc_aso\"])\n",
    "    elif pd.notna(row[\"doc_prod\"]):\n",
    "        documento = int(row[\"doc_prod\"])\n",
    "    else:\n",
    "        documento = None\n",
    "\n",
    "    response = {\n",
    "        \"documento_productor\":documento,\n",
    "        \"poligono\":str(row[\"geometry\"]),\n",
    "        \"mongo_atribute\":{\n",
    "            \"documento\":str(documento),\n",
    "            \"nombre_productor\":str(row[\"nom_prod\"]),\n",
    "            \"area\": row['area'],\n",
    "            \"tipo_arboles\":row['tipo_arb'],\n",
    "            \"fecha_visita\": pd.to_datetime(row['fecha_vis']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_vis']) else None\n",
    "        }\n",
    "    }\n",
    "    response = limpiar_nan(response)\n",
    "    return response\n",
    "\n",
    "def reportar_infraestructura(row):\n",
    "    if pd.notna(row[\"doc_aso\"]):\n",
    "        documento = int(row[\"doc_aso\"])\n",
    "    elif pd.notna(row[\"doc_prod\"]):\n",
    "        documento = int(row[\"doc_prod\"])\n",
    "    else:\n",
    "        documento = None\n",
    "    response = {\n",
    "        \"documento_productor\":documento,\n",
    "        \"poligono\":str(row[\"geometry\"]),\n",
    "        \"mongo_atribute\":{\n",
    "            \"documento\":str(documento),\n",
    "            \"nombre_productor\":str(row[\"nom_prod\"]),\n",
    "            \"area\": row['area'],\n",
    "            \"fecha_visita\": pd.to_datetime(row['fecha_vis']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_vis']) else None,\n",
    "            \"tipo_estructura\": row['tipo_estr'],\n",
    "            \"estructura\": row['estruc_sel']\n",
    "        }\n",
    "    }\n",
    "    response = limpiar_nan(response)\n",
    "    return response\n",
    "\n",
    "def actualizar_fincas_existentes(row):\n",
    "    respuesta={\n",
    "        \"poligono\":str(row[\"geometry\"]),\n",
    "        \"mongo_atribute\":{\n",
    "            \"documento\":row[\"doc_aso\"],\n",
    "            \"nombre_finca\":row[\"nombre_fin\"],\n",
    "            \"fecha_visita\":pd.to_datetime(row['fecha_vis']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_vis']) else None,\n",
    "            \"area\":row[\"area\"]\n",
    "        }\n",
    "    }\n",
    "    response=limpiar_nan(respuesta)\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "def actualizar_lotes_existentes(row):\n",
    "    respuesta = {\n",
    "        \"poligono\":str(row[\"geometry\"]),\n",
    "        \"mongo_atribute\":{\n",
    "                \"numero_documento\": str(row[\"doc_aso\"]),\n",
    "                \"nombre_productor\": str(row['nom_prod']),\n",
    "                \"fecha_visita\": pd.to_datetime(row['fecha_vis']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_vis']) else None,\n",
    "                \"area\": row['area'],\n",
    "                \"observaciones\": \"\",\n",
    "                \"descripcion\": \"\",\n",
    "                \"numero_lote\": None,\n",
    "                \"nombre_pol\":row[\"nombre_pol\"],\n",
    "                \"descripcion_lote\": \"\",\n",
    "                \"variedad\": row['variedad'],\n",
    "                \"distancia_surcos\": row['dist_surco'],\n",
    "                \"distancia_plantas\": row['dist_plant'],\n",
    "                \"densidad\": row['densidad'],\n",
    "                \"numero_plantas\": row['num_planta'],\n",
    "                \"gramos_plantas\": row['gr_plant'],\n",
    "                \"kg_produccion\": row['kg_produc'],\n",
    "                \"fecha_actividad\": pd.to_datetime(row['fecha_acti']).strftime(\"%Y-%m-%d\") if pd.notnull(row['fecha_acti']) else None,\n",
    "                \"produccion\": row['produccion'],\n",
    "                \"estado_cultivo\": row.get('estad_cult') if 'estad_cult' in row and pd.notnull(row['estad_cult']) else None,\n",
    "                \"subtipo_operacion\": row['subtipo_op']\n",
    "            }\n",
    "    }\n",
    "    respuesta = limpiar_nan(respuesta)\n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reporte_coronel(gdf, tipo, metodo_reporte):\n",
    "    respuestas_exitosas_lote = []\n",
    "    respuestas_no_exitosas_lote = []\n",
    "    for i, row in gdf.iterrows():\n",
    "        respuesta = metodo_reporte(row)\n",
    "        print(respuesta)\n",
    "        response = session.post(capas_gdf_dict[tipo], json=respuesta, verify=False)\n",
    "        print(response.status_code)\n",
    "        print(response.json())\n",
    "        if response.ok:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                # Solo guardar si la respuesta incluye un ID o estado positivo\n",
    "                if \"id\" in data or data.get(\"status\") == \"success\":\n",
    "                    respuestas_exitosas_lote.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar JSON en fila {i} del tipo {tipo}: {e}\")\n",
    "        else:\n",
    "            respuestas_no_exitosas_lote.append(response.json())\n",
    "    df_exitoso = pd.DataFrame(respuestas_exitosas_lote)\n",
    "    df_no_exitoso = pd.DataFrame(respuestas_no_exitosas_lote)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(folder_base,f'{tipo[:-4]}.xlsx'), engine='openpyxl') as writer:\n",
    "        df_exitoso.to_excel(writer, sheet_name='rep_suc', index=False)\n",
    "        df_no_exitoso.to_excel(writer, sheet_name='rep_not_suc', index=False)\n",
    "\n",
    "\n",
    "def actualizacion_coronel(gdf, tipo, metodo_reporte):\n",
    "    \n",
    "    respuestas_exitosas_lote = []\n",
    "    respuestas_no_exitosas_lote = []\n",
    "    gdf = gdf.loc[gdf[\"Actualizar\"] == 1]\n",
    "    url = capas_gdf_dict_agrupados[tipo]\n",
    "    gdf = gdf.rename(columns={'id_1': 'id'})\n",
    "    print(gdf)\n",
    "    for i, row in gdf.iterrows():\n",
    "        if pd.isna(row[\"id\"]):\n",
    "            respuestas_exitosas_lote.append({\"objeto\":row, \"razon\": \"lote creado en capa erronea\"})\n",
    "        else:\n",
    "            fecha_ahora = datetime.now()\n",
    "            fecha_formateada = fecha_ahora.strftime(\"%d-%m-%Y_%H--%M--%S\")\n",
    "            url_actualizacion = f\"{url}update/mongo_update/{row['id']}/{fecha_formateada}/\"\n",
    "            respuesta = metodo_reporte(row)\n",
    "            response = session.post(url_actualizacion, json=respuesta, verify=False)\n",
    "            respuesta[\"id\"] = row[\"id\"]\n",
    "            print(response.ok)\n",
    "            print(response.text)\n",
    "            print(response.json())\n",
    "            if response.ok:\n",
    "                respuestas_exitosas_lote.append(respuesta)\n",
    "            else:\n",
    "                respuestas_no_exitosas_lote.append({\"id\":row['id'],\"respuesta\":respuesta})\n",
    "    df_exitoso = pd.DataFrame(respuestas_exitosas_lote)\n",
    "    df_no_exitoso = pd.DataFrame(respuestas_no_exitosas_lote)\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(folder_base,f'{tipo[:-4]}.xlsx'), engine='openpyxl') as writer:\n",
    "        df_exitoso.to_excel(writer, sheet_name='rep_suc', index=False)\n",
    "        df_no_exitoso.to_excel(writer, sheet_name='rep_not_suc', index=False)\n",
    "\n",
    "for tipo, ruta in files_individuales:\n",
    "    if tipo in list(capas_gdf_dict.keys()):\n",
    "        gdf = gpd.read_file(ruta)            \n",
    "        # if tipo == \"Lote.shp\":\n",
    "        #     reporte_coronel(gdf, tipo, reportar_lotes)\n",
    "        if tipo == \"Finca.shp\":\n",
    "            reporte_coronel(gdf, tipo, reportar_fincas)\n",
    "        # if tipo == \"Conservacion.shp\":\n",
    "        #     reporte_coronel(gdf, tipo, reportar_conservacion)\n",
    "        # if tipo == \"Construcciones.shp\":\n",
    "        #     reporte_coronel(gdf, tipo, reportar_infraestructura)\n",
    "\n",
    "# for tipo, ruta in files_agrupados:\n",
    "#     if tipo in list(capas_gdf_dict_agrupados.keys()):\n",
    "#         gdf = gpd.read_file(ruta)\n",
    "#         if tipo == \"Fincas.shp\":\n",
    "#             actualizacion_coronel(gdf, tipo, actualizar_fincas_existentes)\n",
    "#         if tipo.startswith(\"Lote\"):\n",
    "#             gdf[\"gr_plant\"] = pd.to_numeric(gdf[\"gr_plant\"], errors=\"coerce\")\n",
    "#             gdf[\"num_planta\"] = pd.to_numeric(gdf[\"num_planta\"], errors=\"coerce\")\n",
    "#             gdf[\"kg_produc\"] = (gdf[\"gr_plant\"]/1000)*gdf[\"num_planta\"]\n",
    "#             actualizacion_coronel(gdf, tipo, actualizar_lotes_existentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
